{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Basics of scikit-learn package** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import plotly.express as px\n",
    "from plotly.offline import init_notebook_mode\n",
    "import warnings\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning (контролируемое обучение / обучение с учителем)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 *Linear Models (Линейные модели)*\n",
    "\n",
    "Линейные модели являются основой многих методов машинного обучения. Они просты в интерпретации, быстры в обучении и хорошо работают на больших данных. Основная идея линейных моделей заключается в том, что целевая переменная $y$ выражается как линейная комбинация входных признаков $X$:\n",
    "\n",
    "$$\n",
    "y = w_0 + w_1 x_1 + w_2 x_2 + \\dots + w_n x_n + \\varepsilon\n",
    "$$\n",
    "\n",
    "где:\n",
    "- $w_0$ — свободный коэффициент (intercept),\n",
    "- $w_1, \\dots, w_n$ — веса модели (коэффициенты),\n",
    "- $x_1, \\dots, x_n$ — входные признаки,\n",
    "- $\\varepsilon$ — ошибка модели (остаточный член).\n",
    "\n",
    "### 1.1.1 Метод наименьших квадратов (Ordinary Least Squares, OLS)\n",
    "\n",
    "Метод наименьших квадратов минимизирует сумму квадратов ошибок между предсказанными значениями $\\hat{y}$ и реальными значениями $y$:\n",
    "\n",
    "$$\n",
    "J(w) = \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^{m} (y_i - (w_0 + \\sum_{j=1}^{n} w_j x_{ij}))^2\n",
    "$$\n",
    "\n",
    "Оптимальные коэффициенты $w$ находятся по формуле:\n",
    "\n",
    "$$\n",
    "\\mathbf{w} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}\n",
    "$$\n",
    "\n",
    "В scikit-learn линейная регрессия реализуется с помощью `LinearRegression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициенты: [1. 1.]\n",
      "Свободный член: 1.7763568394002505e-15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = [[1, 2], [2, 3], [3, 4], [4, 5]]  # Признаки\n",
    "y = [3, 5, 7, 9]  # Целевая переменная\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"Коэффициенты:\", model.coef_)\n",
    "print(\"Свободный член:\", model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценки коэффициентов для метода наименьших квадратов основаны на независимости признаков. Когда признаки коррелируют и столбцы матрицы признаков $X$\n",
    "имеют приблизительно линейную зависимость, матрица  становится близкой к сингулярной, и в результате оценка наименьших квадратов становится очень чувствительной к случайным ошибкам в наблюдаемой цели, производя большую дисперсию. Такая ситуация мультиколлинеарности может возникнуть, например, когда данные собираются без экспериментального дизайна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно ограничить все коэффициенты неотрицательными значениями, что может быть полезно, когда они представляют некоторые физические или естественно неотрицательные величины (например, частотные показатели или цены товаров). `LinearRegression` принимает булевый параметр `positive` : если установлено значение `True` , то применяются наименьшие квадраты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Линейная регрессия с L2-регуляризацией (Ridge Regression)\n",
    "\n",
    "Ridge-регрессия добавляет L2-регуляризацию (штраф за большие коэффициенты) для предотвращения переобучения:\n",
    "\n",
    "$$\n",
    "J(w) = \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^{n} w_j^2\n",
    "$$\n",
    "\n",
    "где $\\lambda$ — параметр регуляризации. Чем больше $\\lambda$, тем сильнее штраф за большие коэффициенты.\n",
    "\n",
    "Пример реализации Ridge-регрессии в scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициенты Ridge: [0.90909091 0.90909091]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X, y)\n",
    "\n",
    "print(\"Коэффициенты Ridge:\", ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что класс `Ridge` позволяет пользователю указать, что решатель будет выбран автоматически, установив `solver=\"auto\"`. Если указан этот параметр, `Ridge` будет выбирать между решателями `\"lbfgs\"`, `\"cholesky\"` и `\"sparse_cg\"`. `Ridge` начнет проверять условия, показанные в следующей таблице сверху вниз. Если условие истинно, выбирается соответствующий решатель.\n",
    "\n",
    "| Решатель | Состояние |\n",
    "|---------|------------|\n",
    "| `'lbfgs'`    | Параметр `positive=True` указана. |\n",
    "| `\"cholesky\"` | Входной массив X не является разреженным. |\n",
    "| `'sparse_cg'` | Ни одно из вышеперечисленных условий не выполнено. |\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Линейная регрессия с L1-регуляризацией (Lasso Regression)\n",
    "\n",
    "Lasso-регрессия использует L1-регуляризацию, накладывая штраф на сумму абсолютных значений коэффициентов:\n",
    "\n",
    "$$\n",
    "J(w) = \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^{n} |w_j|\n",
    "$$\n",
    "\n",
    "Lasso способствует разреженности модели, зануляя некоторые коэффициенты, что полезно для отбора признаков.\n",
    "\n",
    "Параметр `alpha` контролирует степень разреженности оценочных коэффициентов.\n",
    "\n",
    "Пример в scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициенты Lasso: [1.92000000e+00 1.33226763e-16]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X, y)\n",
    "\n",
    "print(\"Коэффициенты Lasso:\", lasso.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Эластичная сеть (Elastic Net)\n",
    "\n",
    "Elastic Net сочетает L1- и L2-регуляризации:\n",
    "\n",
    "$$\n",
    "J(w) = \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2 + \\lambda_1 \\sum_{j=1}^{n} |w_j| + \\lambda_2 \\sum_{j=1}^{n} w_j^2\n",
    "$$\n",
    "\n",
    "Этот метод особенно полезен, если признаки коррелированы между собой.\n",
    "\n",
    "Пример Elastic Net в scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициенты Elastic Net: [0.96195901 0.9596548 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "elastic_net.fit(X, y)\n",
    "\n",
    "print(\"Коэффициенты Elastic Net:\", elastic_net.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 Логистическая регрессия (Logistic Regression)\n",
    "\n",
    "Логистическая регрессия используется для задач классификации и моделирует вероятность принадлежности объекта к определённому классу с помощью сигмоидной функции:\n",
    "\n",
    "$$\n",
    "P(y=1 | x) = \\frac{1}{1 + e^{- (w_0 + w_1 x_1 + ... + w_n x_n)}}\n",
    "$$\n",
    "\n",
    "Функция потерь для логистической регрессии — логарифмическая:\n",
    "\n",
    "$$\n",
    "J(w) = - \\sum_{i=1}^{m} \\left[ y_i \\log \\hat{y}_i + (1 - y_i) \\log (1 - \\hat{y}_i) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициенты: [[-0.562841   -0.56289585]\n",
      " [-0.16786972 -0.16808781]\n",
      " [ 0.16793833  0.16799842]\n",
      " [ 0.5627724   0.56298524]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X, y)\n",
    "\n",
    "print(\"Коэффициенты:\", log_reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 Байесовская регрессия (Bayesian Regression)\n",
    "\n",
    "Байесовская регрессия учитывает априорное распределение параметров модели, позволяя получать интервальные оценки коэффициентов.\n",
    "\n",
    "Пример использования в scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициенты Bayesian Ridge: [0.99999997 0.99999997]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "bayes_ridge = BayesianRidge()\n",
    "bayes_ridge.fit(X, y)\n",
    "\n",
    "print(\"Коэффициенты Bayesian Ridge:\", bayes_ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
