{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Basics of scikit-learn package** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import plotly.express as px\n",
    "from plotly.offline import init_notebook_mode\n",
    "import warnings\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning (контролируемое обучение / обучение с учителем)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 *Linear Models (Линейные модели)*\n",
    "\n",
    "Линейные модели являются основой многих методов машинного обучения. Они просты в интерпретации, быстры в обучении и хорошо работают на больших данных. Основная идея линейных моделей заключается в том, что целевая переменная $y$ выражается как линейная комбинация входных признаков $X$:\n",
    "\n",
    "$$\n",
    "y = w_0 + w_1 x_1 + w_2 x_2 + \\dots + w_n x_n + \\varepsilon\n",
    "$$\n",
    "\n",
    "где:\n",
    "- $w_0$ — свободный коэффициент (intercept),\n",
    "- $w_1, \\dots, w_n$ — веса модели (коэффициенты),\n",
    "- $x_1, \\dots, x_n$ — входные признаки,\n",
    "- $\\varepsilon$ — ошибка модели (остаточный член).\n",
    "\n",
    "### 1.1.1 Метод наименьших квадратов (Ordinary Least Squares, OLS)\n",
    "\n",
    "Метод наименьших квадратов минимизирует сумму квадратов ошибок между предсказанными значениями $\\hat{y}$ и реальными значениями $y$:\n",
    "\n",
    "$$\n",
    "J(w) = \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^{m} (y_i - (w_0 + \\sum_{j=1}^{n} w_j x_{ij}))^2\n",
    "$$\n",
    "\n",
    "Оптимальные коэффициенты $w$ находятся по формуле:\n",
    "\n",
    "$$\n",
    "\\mathbf{w} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}\n",
    "$$\n",
    "\n",
    "В scikit-learn линейная регрессия реализуется с помощью `LinearRegression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициенты: [1. 1.]\n",
      "Свободный член: 1.7763568394002505e-15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = [[1, 2], [2, 3], [3, 4], [4, 5]]  # Признаки\n",
    "y = [3, 5, 7, 9]  # Целевая переменная\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"Коэффициенты:\", model.coef_)\n",
    "print(\"Свободный член:\", model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Линейная регрессия с L2-регуляризацией (Ridge Regression)\n",
    "\n",
    "Ridge-регрессия добавляет L2-регуляризацию (штраф за большие коэффициенты) для предотвращения переобучения:\n",
    "\n",
    "$$\n",
    "J(w) = \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^{n} w_j^2\n",
    "$$\n",
    "\n",
    "где $\\lambda$ — параметр регуляризации. Чем больше $\\lambda$, тем сильнее штраф за большие коэффициенты.\n",
    "\n",
    "Пример реализации Ridge-регрессии в scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициенты Ridge: [0.90909091 0.90909091]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X, y)\n",
    "\n",
    "print(\"Коэффициенты Ridge:\", ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Линейная регрессия с L1-регуляризацией (Lasso Regression)\n",
    "\n",
    "Lasso-регрессия использует L1-регуляризацию, накладывая штраф на сумму абсолютных значений коэффициентов:\n",
    "\n",
    "$$\n",
    "J(w) = \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^{n} |w_j|\n",
    "$$\n",
    "\n",
    "Lasso способствует разреженности модели, зануляя некоторые коэффициенты, что полезно для отбора признаков.\n",
    "\n",
    "Пример в scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициенты Lasso: [1.92000000e+00 1.33226763e-16]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X, y)\n",
    "\n",
    "print(\"Коэффициенты Lasso:\", lasso.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Эластичная сеть (Elastic Net)\n",
    "\n",
    "Elastic Net сочетает L1- и L2-регуляризации:\n",
    "\n",
    "$$\n",
    "J(w) = \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2 + \\lambda_1 \\sum_{j=1}^{n} |w_j| + \\lambda_2 \\sum_{j=1}^{n} w_j^2\n",
    "$$\n",
    "\n",
    "Этот метод особенно полезен, если признаки коррелированы между собой.\n",
    "\n",
    "Пример Elastic Net в scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициенты Elastic Net: [0.96195901 0.9596548 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "elastic_net.fit(X, y)\n",
    "\n",
    "print(\"Коэффициенты Elastic Net:\", elastic_net.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
